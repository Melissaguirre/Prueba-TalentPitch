# Data Analyst Challenge - TalentPitch

## DescripciÃ³n
Esta soluciÃ³n procesa datos provenientes de archivos CSV alojados en prueba-talentpitch/data para generar mÃ©tricas clave sobre los *Flows* (convocatorias), *Resumes* en video y usuarios en TalentPitch, ademÃ¡s de otros procesos. El sistema automatiza el anÃ¡lisis, genera reportes (PDF y CSV) e indica insights finales.

La soluciÃ³n estÃ¡ desarrollada en **Python 3.10**, para facilitar mantenibilidad, y ejecuciÃ³n a nivel de compatibilidad de versionamiento.


## Problema Resuelto
Se crea un proceso automatizado para:
- Ingesta, validaciÃ³n y limpieza de datos.
- CÃ¡lculo de mÃ©tricas por Flow.
- GeneraciÃ³n de reportes PDF y CSV.
- EnvÃ­o de reportes por correo.

## CaracterÃ­sticas Principales
- Ingesta y lectura de archivos CSV desde /data
- Validaciones automÃ¡ticas: IDs, campos requeridos, FK, emails Ãºnicos.
- CÃ¡lculo de mÃ©tricas por flow: Participantes Ãºnicos, total aplicaciones, votos, visualizaciones, top skills, tasa de conversiÃ³n, mÃ©tricas por perÃ­odo (mensual-semanal).
- GeneraciÃ³n de reportes consolidados en CSV y PDF.
- Persistencia de datos limpios en SQLite para anÃ¡lisis posteriores.

## TecnologÃ­as Utilizadas
- Python 3.10+
- Pandas
- SQLite
- SQLAlchemy
- FPDF
- SendGrid
- Pydantic

## Prerequisitos
- Python 3.10+
- Pip
- pipenv

Variables de entorno
- SENDGRID_API_KEY
- TEMPLATE_ID
- EMAIL_SENDER
- EMAIL_RECEIVER

## InstalaciÃ³n
Sigue estos pasos para preparar el entorno y ejecutar el proyecto localmente.

1. Clona el repositorio y ve al directorio del proyecto:

```bash
git clone <repo-url>
cd Prueba-TalentPitch
```

2. OpciÃ³n recomendada con Pipenv:

```bash
# instalar pipenv si no lo tienes
pip install --user pipenv

# instalar dependencias (incluye dev) y abrir shell
pipenv install --dev
pipenv shell
```

3. Alternativa venv + pip:

```bash
# crear entorno virtual
python3 -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate

# si no existe, puedes crear requirements desde Pipfile con:
# pipenv lock -r > requirements.txt
# e instalar:
pip install -r requirements.txt
```

4. Configura variables de entorno:

```bash
export SENDGRID_API_KEY="<sendgrid-key>"
export TEMPLATE_ID="<template-id>"
export EMAIL_SENDER="sender@example.com"
export EMAIL_RECEIVER="receiver@example.com"
```

## Uso
```bash
# si usas pipenv
pipenv run python src/main.py

# si usas venv
python src/main.py
```

## Estructura del Proyecto

```
Prueba-TalentPitch/
â”œâ”€â”€ Pipfile                    # Dependencias y versiones del proyecto (pipenv)
â”œâ”€â”€ README.md                  
â”‚
â”œâ”€â”€ data/                      # ğŸ“ Archivos CSV de entrada (datos sin procesar)
â”‚   â”œâ”€â”€ flows.csv              # Convocatorias / Flows
â”‚   â”œâ”€â”€ users.csv              # InformaciÃ³n de usuarios
â”‚   â”œâ”€â”€ resumes.csv            # Resumes en video de usuarios
â”‚   â”œâ”€â”€ resumes_exhibited.csv  # Exhibiciones de resumes en flows
â”‚   â”œâ”€â”€ votes.csv              # Votos recibidos en flows/resumes
â”‚   â”œâ”€â”€ shares.csv             # Comparticiones de flows
â”‚   â”œâ”€â”€ views.csv              # Visualizaciones de flows/resumes
â”‚   â””â”€â”€ profiles.csv           # Perfiles adicionales de usuarios
â”‚
â””â”€â”€ src/                       # ğŸ“ CÃ³digo fuente del pipeline
    â”œâ”€â”€ main.py                # Orquestador principal del pipeline
    â”‚
    â”œâ”€â”€ ingestion/             # ğŸ“ MÃ³dulo de ingesta de datos
    â”‚   â””â”€â”€ loader.py          # Lectura de CSVs, carga inicial y validaciÃ³n
    â”‚
    â”œâ”€â”€ processing/            # ğŸ“ MÃ³dulo de procesamiento y cÃ¡lculo de mÃ©tricas
    â”‚   â””â”€â”€ metrics.py         # Funciones para calcular KPIs por Flow
    â”‚                           # (participantes, aplicaciones, votos, skills, etc.)
    â”‚
    â”œâ”€â”€ reporting/             # ğŸ“ MÃ³dulo de generaciÃ³n de reportes
    â”‚   â”œâ”€â”€ reports.py          # Genera mÃ©tricas en formato CSV y PDF, al terminar de generarlos, realiza el envÃ­o de correo con ambos formatos.
    â”‚
    â”œâ”€â”€ db/                    # ğŸ“ MÃ³dulo de persistencia en base de datos
    â”‚   â”œâ”€â”€ database.py        # ConfiguraciÃ³n SQLAlchemy, engine SQLite
    â”‚   â”œâ”€â”€ models.py          # Modelos ORM (Flow, User, Resume, etc.)
    â”‚   â””â”€â”€ save.py            # Persistencia de DataFrames a tablas SQLite
    â”‚
    â””â”€â”€ utils/                 # ğŸ“ Utilidades reutilizables para todo el pipeline
        â”œâ”€â”€ validators.py      # Funciones de validaciÃ³n (IDs, FK, emails, etc.)
        â”œâ”€â”€ schemas.py         # DefiniciÃ³n de campos esperados y relaciones FK
        â”œâ”€â”€ sendgrid.py        # Servicio para el envÃ­o de correos
        |
        â””â”€â”€ logger.py          # ConfiguraciÃ³n de logging
```

### Archivos Clave Explicados

| Archivo | PropÃ³sito |
|---------|-----------|
| `src/main.py` | Punto de entrada; orquesta el flujo: load - validate - save in db - calculate metrics - report |
| `src/ingestion/loader.py` | Lee CSVs de `data/`, valida datos con funciones de `validators.py` |
| `src/processing/metrics.py` | Contiene funciones para calcular KPIs (participantes Ãºnicos, votos, top skills, etc.) |
| `src/reporting/reports.py` | Genera mÃ©tricas en un archivo CSV y en un PDF almacena toda la informaciÃ³n incluyendo grÃ¡ficas, conclusiones, recomendaciones.|
| `src/db/database.py` | Define conexiÃ³n SQLite, activa FK constraints |
| `src/db/models.py` | Modelos SQLAlchemy para las 8 tablas (flows, users, resumes, etc.) |
| `src/db/save.py` | Transforma fechas, convierte DataFrames a registros, realiza el guardado en las tablas.|
| `src/utils/validators.py` | Valida emails Ãºnicos, IDs vÃ¡lidos, FK, campos requeridos |
| `src/utils/schemas.py` | Define campos esperados por tabla y relaciones entre ellas|
| `src/utils/sendgrid.py` | Servicio para envÃ­o automÃ¡tico de reportes por correo |


## Decisiones de DiseÃ±o

- **SeparaciÃ³n por capas modular (ingestion - persistence - processing - reporting)**
  - Cada mÃ³dulo tiene responsabilidad Ãºnica y bien definida, facilitando mantenimiento y evoluciÃ³n independiente.

- **Pandas para ETL**
  - LibrerÃ­a poderosa y flexible para limpieza, transformaciÃ³n y agregaciÃ³n de datos CSV sin complejidad innecesaria.

- **SQLite + SQLAlchemy**
  - Base de datos liviana sin servidor, perfecta para desarrollo y datasets pequeÃ±os-medianos.
  - ORM permite mapeo transparente entre DataFrames y tablas, eliminando SQL manual.

- **FPDF para reportes PDF**
  - Genera PDF con tablas, grÃ¡ficas y resumen ejecutivo sin dependencias pesadas.

- **SendGrid para envÃ­o de correos**
  - IntegraciÃ³n sencilla y confiable para distribuir reportes automÃ¡ticamente.

- **Pydantic para validaciÃ³n de datos**
  - Garantiza que los datos cumplen esquemas esperados, mejorando robustez.


## CÃ³mo Se Ejecuta la SoluciÃ³n

El pipeline sigue este flujo paso a paso:

1. **Carga de datos** (`src/ingestion/loader.py`)
   - Lee cada CSV en `data/` segÃºn esquema definido en `src/utils/schemas.py`
   - Llama a `complete_validations()` para cada tabla

2. **Validaciones** (`src/utils/validators.py`)
   - Elimina emails duplicados
   - Remueve filas con campos requeridos faltantes
   - Valida IDs (elimina nulos, duplicados, mantiene los mÃ¡s recientes)
   - Valida referencias FK (elimina filas cuyas FK no existen en tablas referenciadas)

3. **Persistencia** (`src/db/save.py`)
   - Convierte tipos de datos (fechas)
   - Hace bulk insert de todos los DataFrames a tablas SQLite
   - Si hay error, rollback automÃ¡tico para mantener integridad


4. **CÃ¡lculo de mÃ©tricas** (`src/processing/metrics.py`)
   - Agrupa datos por Flow para calcular:
     - Participantes Ãºnicos, total aplicaciones, votos totales
     - Visualizaciones Ãºnicas y totales, compartidos
     - DistribuciÃ³n por gÃ©nero y rango de edad
     - Top skills mÃ¡s comunes
     - Tasa de conversiÃ³n (participantes / aplicaciones) * 100
     - MÃ©tricas por mes y semana

5. **GeneraciÃ³n de reportes** (`src/reporting/reports.py`)
   - Genera CSV multi-secciÃ³n con todas las mÃ©tricas
   - Crea PDF con tablas, grÃ¡ficas, resumen ejecutivo y recomendaciones

6. **EnvÃ­o de correos** (`src/utils/sendgrid.py`)
   - EnvÃ­a automÃ¡ticamente CSV y PDF a direcciones configuradas via SENDGRID_API_KEY
   **importante: (Actualmente los correos llegan a spam con mi configuraciÃ³n actual)**

7. **FinalizaciÃ³n**
   - Logs informativos en cada paso
   - Archivos finales disponibles: `talentpitch_data_clean.db`

## Resultados Esperados

Tras ejecutar `pipenv run python src/main.py` (o `python src/main.py` con venv), obtendrÃ¡s:

### Archivos de salida:

2. **`talentpitch_data_clean.db`**
   - Base SQLite con 8 tablas:
     - `flows`, `users`, `resumes`, `resumes_exhibited`
     - `votes`, `shares`, `views`, `profiles`
   - Datos limpios (validados, sin duplicados, con FK intactas)

4. **Correos enviados**
   - CSV y PDF automÃ¡ticamente distribuidos a `EMAIL_RECEIVER` via SendGrid

### Ejemplo de logs esperados:

```
2025-12-02 10:30:00 - INFO - root - Loading data from CSV files
2025-12-02 10:30:01 - INFO - root - Loading flows
2025-12-02 10:30:01 - INFO - root - Validating unique emails
...
2025-12-02 10:30:05 - INFO - root - Mail sent successfully
2025-12-02 10:30:06 - INFO - root - Data process complete
```

## Testing
[CÃ³mo ejecutar los tests y quÃ© cobertura tienen]